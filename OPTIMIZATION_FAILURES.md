# Architecture Optimization Failure Log

> **마지막 업데이트**: 2026-03-01
> 이 문서는 Beast JSON 라이브러리 개발 중 각 아키텍처(x86_64, aarch64 등)별로 시도되었으나 실패(성능 회귀, Regression)한 최적화 사례와 그 원인을 면밀히 분석한 자료입니다.
> 에이전트는 새로운 SIMD 최적화를 시도하기 전에 **반드시 이 문서를 숙지**하여 동일한 실수를 반복하지 않도록 해야 합니다.

---

## 1. aarch64 (NEON) 최적화 회귀 사례

### ❌ [Phase 49 시도] NEON 64B (4×16B) 구조적 스캐너 및 공백 스킵 처리
* **목표**: x86_64의 AVX-512 64B 청크 단위 스캐닝(`_mm512_loadu_si512` 등) 성능 개선을 벤치마킹하여, NEON에서도 16바이트(`uint8x16_t`) 4개를 한 번에 언롤링(Unrolling)하여 64B 단위로 처리.
* **적용 대상**: `skip_to_action()`, `scan_string_end()`, `scan_key_colon_next()`
* **실패 결과 (성능 대폭 하락)**: 
  * `twitter.json`: 269μs -> 360μs (+33% 회귀)
  * `citm_catalog.json`: 639μs -> 1037μs (+62% 회귀)
  * `gsoc-2018.json`: 627μs -> 885μs (+41% 회귀)
* **근본 원인 분석**:
  1. **명령어 집합의 근본적 차이**: AVX-512는 64바이트를 '단 하나의 명령어'(`__m512i`)로 로드/비교/비트마스크 변환이 가능합니다. 하지만 NEON에는 64바이트 단일 벡터 레지스터가 존재하지 않습니다. 
  2. **레지스터 스필(Register Spill) 및 중첩 연산 과부하**: 로드(`vld1q_u8`) × 4번, 비교(`vcgtq_u8`, `vceqq_u8`) × 4번 이상, 합산(`vorrq_u8`) 연속 3번 이상이 핫 루프에 추가되면서 컴파일러의 레지스터 할당 한계를 초과하여 CPU 파이프라인이 심각하게 스톨(Stall)되었습니다.
  3. **비트마스크 병목**: AVX는 `_mm512_cmpgt_epi8_mask` 하나로 64비트 정수(mask)를 바로 뽑아내어 `__builtin_ctzll`로 분기가 빠릅니다. 반면 NEON에는 기본 `movemask` 명령이 없어 `vmaxvq_u32`로 1차 판별 후 `neon_movemask()` 유틸리티 함수(시프트, 곱 연산, 리덕션 트리 사용)를 추가 호출해야 하므로 4개의 16B 마스크를 OR로 모아서 처리하는 과정의 연산 비용이 루프를 4번 도는 비용보다 훨씬 컸습니다.
  4. **진입 비용(Startup Overhead) 극대화**: `twitter.json` 등은 문자열이나 공백의 런(run) 스팬이 매우 짧습니다. 64B 크기를 뭉텅이로 처리하기 전 진입하는 셋업/조건 비용 자체가 커서, 오히려 16바이트로 빠르게 스킵하고 즉각 탈출하는 것이 aarch64 아키텍처에서 가장 효율적인 파레토 최적 지점이었습니다.
* **가이드라인 (에이전트 수칙)**:
  * **AArch64 에이전트**: NEON에서 32바이트 이상을 루프 언롤링하여 억지로 처리하려 하지 마세요. NEON 환경은 `uint8x16_t`를 1~2개 처리하는 수준에서 분기를 최소화하는 루프가 최적입니다. x86_64의 AVX-512 극단적 기법을 NEON에 1:1로 이식하려 시도하지 마세요.

---

## 2. x86_64 (AVX2 / AVX-512) 최적화 회귀 사례

### ❌ [Phase 37] AVX2 공백 스킵 스캐닝 (Whitespace Skip)
* **목표**: `skip_to_action()` 함수에서 SWAR-32/SWAR-8 대신 `__m256i` 기반 AVX2 최적화를 도입하여 공백 무시 속도를 극대화.
* **실패 결과**: 전체적으로 **+13% 파싱 시간 증가 (성능 하락)**.
* **근본 원인 분석**:
  * 공백 길이에 대한 JSON 데이터의 '분포'를 간과했습니다. 대부분의 JSON 파일(특히 `twitter.json`)에서 토큰 사이의 공백은 고작 1~8바이트 수준에 불과합니다.
  * AVX2 레지스터에 값을 로딩(set)하고 `_mm256_movemask_epi8` 결과를 뽑아내어 `ctz`를 수행하는 진입 지연(Setup/Teardown Overhead)이, 고작 평균 2~3바이트의 공백을 스킵하는 이득보다 수 배 이상 컸습니다.
* **해결법 (Phase 46)**: AVX-512 64B 스킵퍼 도입 시, **반드시 직전에 SWAR-8(8바이트 체크) Pre-gate를 배치**하여, 8바이트 미만의 공백은 SIMD 레지스터를 깨우지 않고 스칼라단에서 즉시 처리 후 탈출하게 만들었습니다. 

### ❌ [Phase 40] AVX2 벡터 상수 호이스팅 (Constant Hoisting)
* **목표**: SIMD 스캐너 내부에서 매 루프 선언하는 상수 벡터(`_mm256_set1_epi8('"')` 등)를 루프 바깥 혹은 클래스 멤버로 호이스팅(끌어올림)하여 생성 오버헤드를 줄이려는 시도.
* **실패 결과**: 의도와 정반대로 **+10~14% 성능 회귀** 발생.
* **근본 원인 분석**:
  * 현대 x86 컴파일러(GCC, Clang)는 SIMD 함수 내 상수 선언을 보면, 레지스터 할당 스크래치패드를 분석해 완벽한 위치에 `vbroadcast` 시키거나 `.rodata` 참조로 최적화해냅니다.
  * 프로그래머가 이를 억지로 루프 바깥으로 끄집어내면 레지스터 압력이 증가(Register Pressure)하여 오히려 컴파일러가 해당 레지스터 값을 스택에 Spill/Reload 하는 최악의 코드를 생성합니다.
* **가이드라인 (에이전트 수칙)**:
  * **x86_64 에이전트**: SIMD 상수는 **항상 사용 지점(스코프)에 가장 가깝게(인접 선언)** `const __m256i v = _mm256_set1...` 형태로 선언할 것. 컴파일러의 레지스터 프로모션을 절대 방해하지 마세요. (AVX-512도 동일)
